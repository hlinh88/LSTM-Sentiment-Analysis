{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "import tweepy as tw\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up token API"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "api_key = \"HAcIeikl6eRheQP1oKYGDwPx0\"\n",
    "api_secret = \"gEWmqG7QVXzudnviUXDo98L2UKGYg9PNqy1bAR1geClkHjqBGk\"\n",
    "access_token = \"1481095074465579008-1pApYlU4HRJWpbAXcbdVEVGzdACuEz\"\n",
    "access_token_secret = \"htgD81H4mOxXw5MglAljFRHhcfGAuwsNomXVqvGw0Obwe\"\n",
    "auth = tw.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth,wait_on_rate_limit=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Crawl data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon News\n",
      "Amazon Stock\n"
     ]
    }
   ],
   "source": [
    "number_of_tweets = 100\n",
    "tweets = []\n",
    "user_id =[]\n",
    "created_at = []\n",
    "keyword_list = ['News', 'Stock'] # , 'Customers', 'Employees', 'Company', 'Price', 'Shareholders', 'Market', 'Soaring', 'Trends'\n",
    "company = 'Amazon'\n",
    "final_kw_list = []\n",
    "\n",
    "# Crawl data from keywords\n",
    "for i in range (len(keyword_list)):\n",
    "    kw = str(company + ' ' + keyword_list[i])\n",
    "    print(kw)\n",
    "    final_kw_list.append(kw)\n",
    "    for i in tw.Cursor(api.search, q = kw , lang =\"en\", since = \"2022-01-14\",tweet_mode = \"extended\").items(number_of_tweets):\n",
    "        tweets.append(i.full_text)\n",
    "        user_id.append(i.user.id)\n",
    "        created_at.append(i.created_at)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "             Created_at              User_id  \\\n0   2022-02-07 05:27:43   781709113713684480   \n1   2022-02-07 05:26:32            109064246   \n2   2022-02-07 05:26:30  1405283490422087683   \n3   2022-02-07 05:25:15   811414973985550336   \n4   2022-02-07 05:25:01             32518396   \n..                  ...                  ...   \n195 2022-02-07 03:54:33  1404406896220676099   \n196 2022-02-07 03:52:37            499672969   \n197 2022-02-07 03:52:20  1377519267143376898   \n198 2022-02-07 03:52:00             36293735   \n199 2022-02-07 03:51:19  1483308115546509312   \n\n                                                Tweets  \n0    RT @BBCBusiness: Amazon and Nike exploring Pel...  \n1    RT @JoshuaPotash: Here's the full article. And...  \n2    RT @JoshuaPotash: Here's the full article. And...  \n3    RT @JoshuaPotash: Here's the full article. And...  \n4    RT @OccupyDemocrats: If youâ€™re a Democrat who ...  \n..                                                 ...  \n195  GeForce RTX 3070 - PNY - XLR8 Gaming REVEL is ...  \n196  (US)In Stock: XFX Speedster QICK210 Radeon RX ...  \n197  Xbox Series S is now in stock. \\nATC: https://...  \n198  Amazon and Nike are considering making a bid f...  \n199  Open order app premium\\n-ðŸ’¯trusted+garansi\\n-fa...  \n\n[200 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Created_at</th>\n      <th>User_id</th>\n      <th>Tweets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-02-07 05:27:43</td>\n      <td>781709113713684480</td>\n      <td>RT @BBCBusiness: Amazon and Nike exploring Pel...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-02-07 05:26:32</td>\n      <td>109064246</td>\n      <td>RT @JoshuaPotash: Here's the full article. And...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-02-07 05:26:30</td>\n      <td>1405283490422087683</td>\n      <td>RT @JoshuaPotash: Here's the full article. And...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-02-07 05:25:15</td>\n      <td>811414973985550336</td>\n      <td>RT @JoshuaPotash: Here's the full article. And...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-02-07 05:25:01</td>\n      <td>32518396</td>\n      <td>RT @OccupyDemocrats: If youâ€™re a Democrat who ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>2022-02-07 03:54:33</td>\n      <td>1404406896220676099</td>\n      <td>GeForce RTX 3070 - PNY - XLR8 Gaming REVEL is ...</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>2022-02-07 03:52:37</td>\n      <td>499672969</td>\n      <td>(US)In Stock: XFX Speedster QICK210 Radeon RX ...</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>2022-02-07 03:52:20</td>\n      <td>1377519267143376898</td>\n      <td>Xbox Series S is now in stock. \\nATC: https://...</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>2022-02-07 03:52:00</td>\n      <td>36293735</td>\n      <td>Amazon and Nike are considering making a bid f...</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>2022-02-07 03:51:19</td>\n      <td>1483308115546509312</td>\n      <td>Open order app premium\\n-ðŸ’¯trusted+garansi\\n-fa...</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Created_at\": created_at,\"User_id\": user_id,\"Tweets\":tweets})\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "df = df[~df.Tweets.str.contains(\"RT\")]\n",
    "df = df.reset_index(drop = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "def clean_up_tweet(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+','',text) # Remove mentions @\n",
    "    text = re.sub(r'#', '', text) # Remove hastag symbol\n",
    "    text = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', text) # Remove hyper link\n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # Remove special characters\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    #Remove stop words\n",
    "    res = ''\n",
    "    for word in text.split():\n",
    "        if word not in stopwords.words('english'):\n",
    "            res += WordNetLemmatizer().lemmatize(word) + ' '\n",
    "\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk import TweetTokenizer, PorterStemmer\n",
    "\n",
    "\n",
    "#Preprocessing tweets\n",
    "def process_tweet(tweet):\n",
    "\n",
    "    # instantiate tokenizer class\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "\n",
    "    # tokenize tweets\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    #Import the english stop words list from NLTK\n",
    "    stopwords_english = stopwords.words('english')\n",
    "\n",
    "    #Creating a list of words without stopwords\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if word not in stopwords_english and word not in string.punctuation:\n",
    "            tweets_clean.append(word)\n",
    "\n",
    "    # Instantiate stemming class\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    # Creating a list of stems of words in tweet\n",
    "    tweets_stem = []\n",
    "    for word in tweets_clean:\n",
    "        stem_word = stemmer.stem(word)\n",
    "        tweets_stem.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "data": {
      "text/plain": "            Created_at              User_id  \\\n0  2022-02-07 05:24:27  1267197215635726336   \n1  2022-02-07 05:20:37            730176654   \n2  2022-02-07 05:20:03  1267197215635726336   \n3  2022-02-07 05:19:40           1287568658   \n4  2022-02-07 05:12:00   867593107956654080   \n..                 ...                  ...   \n61 2022-02-07 04:09:41  1418587410384908293   \n62 2022-02-07 04:04:53  1418587410384908293   \n63 2022-02-07 03:59:57           3396302147   \n64 2022-02-07 03:52:00             36293735   \n65 2022-02-07 03:51:19  1483308115546509312   \n\n                                               Tweets  \\\n0   lt Ethereum Price gt ETH USDT Binance Check Pr...   \n1   Amazon India sign MoU turn rural woman entrepr...   \n2   lt Binance Coin Price gt BNB USDT Binance Chec...   \n3   FB venue share family news Spotify Rogan preju...   \n4   Watch Whitestone Dome display protector return...   \n..                                                ...   \n61  US In Stock PowerColor Hellhound AMD Radeon RX...   \n62  US In Stock XFX Speedster SWFT Radeon RX CORE ...   \n63  Peloton stock shoot higher report Amazon acqui...   \n64  Amazon Nike considering making bid Peloton Pel...   \n65  Open order app premium trusted garansi fast re...   \n\n                                            Word_list  Compound Sentiment  \n0   [lt, ethereum, price, gt, eth, usdt, binance, ...    0.9042         1  \n1   [amazon, india, sign, mou, turn, rural, woman,...    0.1779         1  \n2   [lt, binance, coin, price, gt, bnb, usdt, bina...    0.9042         1  \n3   [fb, venue, share, family, news, spotify, roga...   -0.1779         0  \n4   [watch, whitestone, dome, display, protector, ...    0.5994         1  \n..                                                ...       ...       ...  \n61  [us, stock, powercolor, hellhound, amd, radeon...    0.3400         1  \n62  [us, stock, xfx, speedster, swft, radeon, rx, ...    0.3400         1  \n63  [peloton, stock, shoot, higher, report, amazon...    0.3182         1  \n64  [amazon, nike, considering, making, bid, pelot...    0.3400         1  \n65  [open, order, app, premium, trusted, garansi, ...    0.5859         1  \n\n[66 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Created_at</th>\n      <th>User_id</th>\n      <th>Tweets</th>\n      <th>Word_list</th>\n      <th>Compound</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-02-07 05:24:27</td>\n      <td>1267197215635726336</td>\n      <td>lt Ethereum Price gt ETH USDT Binance Check Pr...</td>\n      <td>[lt, ethereum, price, gt, eth, usdt, binance, ...</td>\n      <td>0.9042</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-02-07 05:20:37</td>\n      <td>730176654</td>\n      <td>Amazon India sign MoU turn rural woman entrepr...</td>\n      <td>[amazon, india, sign, mou, turn, rural, woman,...</td>\n      <td>0.1779</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-02-07 05:20:03</td>\n      <td>1267197215635726336</td>\n      <td>lt Binance Coin Price gt BNB USDT Binance Chec...</td>\n      <td>[lt, binance, coin, price, gt, bnb, usdt, bina...</td>\n      <td>0.9042</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-02-07 05:19:40</td>\n      <td>1287568658</td>\n      <td>FB venue share family news Spotify Rogan preju...</td>\n      <td>[fb, venue, share, family, news, spotify, roga...</td>\n      <td>-0.1779</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-02-07 05:12:00</td>\n      <td>867593107956654080</td>\n      <td>Watch Whitestone Dome display protector return...</td>\n      <td>[watch, whitestone, dome, display, protector, ...</td>\n      <td>0.5994</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>2022-02-07 04:09:41</td>\n      <td>1418587410384908293</td>\n      <td>US In Stock PowerColor Hellhound AMD Radeon RX...</td>\n      <td>[us, stock, powercolor, hellhound, amd, radeon...</td>\n      <td>0.3400</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>2022-02-07 04:04:53</td>\n      <td>1418587410384908293</td>\n      <td>US In Stock XFX Speedster SWFT Radeon RX CORE ...</td>\n      <td>[us, stock, xfx, speedster, swft, radeon, rx, ...</td>\n      <td>0.3400</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>2022-02-07 03:59:57</td>\n      <td>3396302147</td>\n      <td>Peloton stock shoot higher report Amazon acqui...</td>\n      <td>[peloton, stock, shoot, higher, report, amazon...</td>\n      <td>0.3182</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>2022-02-07 03:52:00</td>\n      <td>36293735</td>\n      <td>Amazon Nike considering making bid Peloton Pel...</td>\n      <td>[amazon, nike, considering, making, bid, pelot...</td>\n      <td>0.3400</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>2022-02-07 03:51:19</td>\n      <td>1483308115546509312</td>\n      <td>Open order app premium trusted garansi fast re...</td>\n      <td>[open, order, app, premium, trusted, garansi, ...</td>\n      <td>0.5859</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>66 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "df['Tweets'] = df['Tweets'].apply(clean_up_tweet)\n",
    "df = df.drop_duplicates(subset='Tweets')\n",
    "df = df.reset_index(drop=True)\n",
    "df['Word_list'] = df['Tweets'].apply(process_tweet)\n",
    "\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "df['Compound'] = [sentiments.polarity_scores(i)[\"compound\"] for i in df[\"Tweets\"]]\n",
    "score = df[\"Compound\"].values\n",
    "sentiment = []\n",
    "for i in score:\n",
    "    if i >= 0.05 :\n",
    "        sentiment.append(1)\n",
    "    elif i <= -0.05 :\n",
    "        sentiment.append(0)\n",
    "    else:\n",
    "        sentiment.append('Neutral')\n",
    "df[\"Sentiment\"] = sentiment\n",
    "df.drop(df.loc[df['Sentiment']=='Neutral'].index, inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building Frequency dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "#Frequency generating function\n",
    "def build_frequency(tweets, ys):\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            freqs[pair] = freqs.get(pair, 0) + 1\n",
    "\n",
    "    return freqs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "{('lt', 1): 16,\n ('ethereum', 1): 5,\n ('price', 1): 18,\n ('gt', 1): 18,\n ('eth', 1): 6,\n ('usdt', 1): 8,\n ('binance', 1): 17,\n ('check', 1): 8,\n ('headline', 1): 8,\n ('news', 1): 19,\n ('cedi', 1): 2,\n ('osman', 1): 2,\n ('kevin', 1): 2,\n ('love', 1): 6,\n ('team', 1): 3,\n ('lead', 1): 2,\n ('cavaliers', 1): 2,\n ('biggest', 1): 2,\n ('comeback', 1): 2,\n ('win', 1): 2,\n ('year', 1): 2,\n ('pacers', 1): 2,\n ('bi', 1): 1,\n ('amazon', 1): 41,\n ('india', 1): 2,\n ('sign', 1): 1,\n ('mou', 1): 1,\n ('turn', 1): 1,\n ('rural', 1): 1,\n ('woman', 1): 1,\n ('entrepreneur', 1): 2,\n ('karnataka', 1): 1,\n ('via', 1): 1,\n ('binaryic', 1): 1,\n ('marketplace', 1): 1,\n ('coin', 1): 3,\n ('bnb', 1): 6,\n ('fb', 0): 1,\n ('venue', 0): 1,\n ('share', 0): 1,\n ('family', 0): 1,\n ('news', 0): 6,\n ('spotify', 0): 1,\n ('rogan', 0): 1,\n ('prejudicial', 0): 1,\n ('hol', 0): 1,\n ('get', 0): 2,\n ('music', 0): 1,\n ('podcasts', 0): 1,\n ('amazon', 0): 19,\n ('watch', 1): 1,\n ('whitestone', 1): 1,\n ('dome', 1): 5,\n ('display', 1): 1,\n ('protector', 1): 3,\n ('return', 1): 1,\n ('pixel', 1): 3,\n ('pro', 1): 3,\n ('big', 1): 1,\n ('sale', 1): 3,\n ('glass', 1): 6,\n ('whitestonedome', 1): 1,\n ('really', 0): 1,\n ('apple', 0): 3,\n ('buy', 0): 1,\n ('peloton', 0): 2,\n ('one', 0): 1,\n ('analyst', 0): 1,\n ('explains', 0): 1,\n ('barron', 0): 1,\n ('ceo', 1): 1,\n ('confirmed', 1): 1,\n ('th', 1): 1,\n ('february', 1): 1,\n ('buydogecoin', 1): 1,\n ('crypto', 1): 1,\n ('cryptonews', 1): 1,\n ('cryptocurrency', 1): 1,\n ('currency', 1): 1,\n ('doge', 1): 1,\n ('dogecoin', 1): 2,\n ('dogecoinelonmusk', 1): 1,\n ('dogecoinexplained', 1): 1,\n ('dogecoinexplosion', 1): 1,\n ('dogecoinlive', 1): 1,\n ('dogecoinnews', 1): 1,\n ('dogecoinnewstoday', 1): 1,\n ('andy', 1): 1,\n ('vermaut', 1): 1,\n ('share', 1): 1,\n ('climate', 1): 4,\n ('change', 1): 4,\n ('top', 1): 5,\n ('company', 1): 5,\n ('exaggerating', 1): 4,\n ('progress', 1): 4,\n ('study', 1): 4,\n ('companies', 1): 2,\n ('including', 1): 3,\n ('google', 1): 2,\n ('ikea', 1): 1,\n ('meeting', 1): 1,\n ('green', 1): 1,\n ('target', 1): 2,\n ('report', 1): 3,\n ('find', 1): 1,\n ('thank', 1): 1,\n ('wheel', 1): 1,\n ('time', 1): 3,\n ('picked', 1): 1,\n ('season', 1): 2,\n ('possibly', 1): 1,\n ('fantastic', 1): 1,\n ('really', 1): 2,\n ('enjoyed', 1): 1,\n ('st', 1): 1,\n ('book', 1): 7,\n ('think', 1): 1,\n ('potential', 1): 2,\n ('great', 1): 1,\n ('show', 1): 2,\n ('given', 1): 1,\n ('proper', 1): 1,\n ('grow', 1): 1,\n ('breaking', 1): 1,\n ('ordered', 1): 1,\n ('pack', 1): 1,\n ('white', 1): 1,\n ('sock', 1): 1,\n ('peloton', 1): 8,\n ('draws', 1): 1,\n ('interest', 1): 2,\n ('buyers', 1): 1,\n ('ottawa', 1): 4,\n ('trucker', 1): 3,\n ('convoy', 1): 3,\n ('galvanizes', 1): 3,\n ('far', 1): 3,\n ('right', 1): 3,\n ('worldwide', 1): 3,\n ('politico', 1): 3,\n ('euphoria', 1): 2,\n ('mary', 1): 4,\n ('mattthomas', 1): 4,\n ('buschlightclash', 1): 3,\n ('lu', 1): 1,\n ('ripple', 1): 4,\n ('xrp', 1): 6,\n ('cassie', 1): 2,\n ('luka', 1): 1,\n ('binancepay', 1): 2,\n ('zendaya', 1): 2,\n ('perfect', 1): 1,\n ('timing', 1): 1,\n ('raises', 1): 1,\n ('prime', 1): 4,\n ('membership', 1): 2,\n ('prices', 1): 2,\n ('users', 1): 1,\n ('across', 1): 1,\n ('united', 1): 1,\n ('states', 1): 1,\n ('properly', 1): 1,\n ('positioning', 1): 1,\n ('way', 1): 2,\n ('ahead', 1): 1,\n ('curve', 1): 1,\n ('want', 1): 1,\n ('free', 1): 1,\n ('mikaela', 1): 1,\n ('shiffrin', 1): 1,\n ('fall', 1): 1,\n ('giant', 1): 1,\n ('slalom', 1): 1,\n ('disqualified', 1): 1,\n ('event', 1): 1,\n ('bird', 1): 1,\n ('box', 1): 1,\n ('community', 1): 1,\n ('credit', 1): 1,\n ('karma', 1): 1,\n ('health', 1): 1,\n ('inssurance', 1): 1,\n ('quote', 1): 1,\n ('mesothelioma', 1): 1,\n ('survival', 1): 1,\n ('rate', 1): 1,\n ('netflix', 1): 1,\n ('nyt', 1): 1,\n ('today', 1): 1,\n ('usa', 1): 2,\n ('last', 1): 2,\n ('todaytrump', 1): 1,\n ('lates', 1): 1,\n ('ranks', 1): 1,\n ('fortune', 1): 1,\n ('world', 1): 2,\n ('admired', 1): 1,\n ('truthbillboards', 0): 1,\n ('amp', 0): 2,\n ('legalnamefraud', 0): 1,\n ('complicit', 0): 1,\n ('illegal', 0): 2,\n ('use', 0): 1,\n ('legal', 0): 1,\n ('name', 0): 1,\n ('kogdotnet', 0): 1,\n ('bccrss', 0): 1,\n ('idsillegal', 0): 1,\n ('newsnight', 0): 1,\n ('much', 1): 1,\n ('amazing', 1): 1,\n ('raising', 1): 1,\n ('aircraft', 0): 1,\n ('fuel', 0): 1,\n ('help', 0): 1,\n ('drive', 0): 1,\n ('mining', 0): 1,\n ('yahoo', 0): 2,\n ('latest', 0): 2,\n ('headlines', 0): 1,\n ('westcoast', 0): 1,\n ('iphone', 0): 1,\n ('price', 0): 3,\n ('drop', 0): 1,\n ('several', 0): 1,\n ('offer', 0): 2,\n ('announced', 0): 1,\n ('flipkart', 0): 1,\n ('check', 0): 2,\n ('deal', 0): 1,\n ('pet', 1): 1,\n ('tpu', 1): 1,\n ('tempered', 1): 2,\n ('choose', 1): 1,\n ('screen', 1): 2,\n ('first', 1): 2,\n ('e', 1): 2,\n ('jig', 1): 1,\n ('galaxy', 1): 2,\n ('ultra', 1): 2,\n ('bbc', 1): 3,\n ('earthquake', 1): 2,\n ('bucks', 1): 2,\n ('normanpowel', 1): 1,\n ('normanp', 1): 1,\n ('exploring', 1): 1,\n ('offer', 1): 2,\n ('source', 1): 1,\n ('say', 1): 3,\n ('nike', 1): 5,\n ('also', 1): 1,\n ('weighing', 1): 1,\n ('bid', 1): 2,\n ('amazoncom', 1): 1,\n ('pandemic', 1): 1,\n ('fitness', 1): 1,\n ('reportedly', 1): 1,\n ('thinking', 1): 1,\n ('buying', 1): 1,\n ('google', 0): 1,\n ('ikea', 0): 1,\n ('among', 0): 1,\n ('company', 0): 4,\n ('failing', 0): 1,\n ('change', 0): 2,\n ('quickly', 0): 1,\n ('enough', 0): 1,\n ('climatecrisis', 0): 1,\n ('gonna', 0): 1,\n ('talk', 0): 1,\n ('real', 0): 1,\n ('shit', 0): 1,\n ('right', 0): 1,\n ('every', 0): 1,\n ('source', 0): 2,\n ('longer', 0): 1,\n ('talking', 0): 3,\n ('thing', 0): 1,\n ('going', 0): 2,\n ('weather', 0): 1,\n ('things', 0): 1,\n ('go', 0): 3,\n ('trending', 0): 1,\n ('day', 0): 1,\n ('everyone', 0): 1,\n ('stop', 0): 1,\n ('still', 0): 1,\n ('fire', 0): 3,\n ('year', 0): 1,\n ('raised', 1): 2,\n ('bumped', 1): 1,\n ('annual', 1): 1,\n ('latest', 1): 1,\n ('hike', 1): 1,\n ('represents', 1): 1,\n ('increase', 1): 1,\n ('second', 1): 1,\n ('gen', 1): 1,\n ('echo', 1): 1,\n ('back', 1): 2,\n ('secret', 0): 1,\n ('trick', 0): 1,\n ('slash', 0): 1,\n ('echo', 0): 1,\n ('tv', 0): 1,\n ('stick', 0): 1,\n ('kindle', 0): 1,\n ('tablet', 0): 1,\n ('ereaders', 0): 1,\n ('daily', 0): 1,\n ('express', 0): 1,\n ('business', 0): 1,\n ('headline', 0): 1,\n ('technology', 0): 1,\n ('computing', 0): 1,\n ('bu', 1): 1,\n ('forgot', 1): 1,\n ('mention', 1): 1,\n ('email', 1): 1,\n ('program', 1): 1,\n ('went', 1): 1,\n ('kaput', 1): 1,\n ('call', 1): 1,\n ('tech', 1): 2,\n ('support', 1): 1,\n ('good', 1): 2,\n ('resistance', 1): 1,\n ('girl', 1): 1,\n ('uk', 1): 3,\n ('kindle', 1): 1,\n ('monthly', 1): 1,\n ('deal', 1): 1,\n ('juliana', 1): 1,\n ('discovers', 1): 1,\n ('grandmamma', 1): 1,\n ('french', 1): 1,\n ('film', 1): 1,\n ('star', 1): 1,\n ('occupied', 1): 1,\n ('paris', 1): 1,\n ('amp', 1): 2,\n ('shocking', 1): 1,\n ('secret', 1): 1,\n ('alexa', 1): 4,\n ('skill', 1): 1,\n ('live', 1): 1,\n ('us', 1): 10,\n ('canada', 1): 1,\n ('australia', 1): 1,\n ('start', 1): 1,\n ('artefaktor', 1): 3,\n ('radio', 1): 3,\n ('open', 1): 2,\n ('play', 1): 1,\n ('grocer', 1): 1,\n ('swapped', 1): 1,\n ('trader', 1): 1,\n ('joe', 1): 1,\n ('silver', 1): 1,\n ('spring', 1): 1,\n ('development', 1): 1,\n ('lenders', 0): 1,\n ('plan', 0): 2,\n ('open', 0): 1,\n ('bidding', 0): 1,\n ('future', 0): 1,\n ('retail', 0): 1,\n ('ril', 0): 1,\n ('revival', 0): 1,\n ('fails', 0): 1,\n ('futureretail', 0): 1,\n ('frl', 0): 1,\n ('futureretailloan', 0): 1,\n ('kishorebiyani', 0): 1,\n ('reliance', 0): 1,\n ('rbi', 0): 1,\n ('ps', 1): 1,\n ('restock', 1): 2,\n ('expect', 1): 1,\n ('console', 1): 1,\n ('appear', 1): 1,\n ('best', 1): 2,\n ('buy', 1): 2,\n ('walmart', 1): 2,\n ('gamestop', 1): 1,\n ('xbox', 1): 1,\n ('series', 1): 1,\n ('x', 1): 2,\n ('update', 1): 1,\n ('retailer', 1): 1,\n ('stock', 1): 21,\n ('asus', 1): 2,\n ('tuf', 1): 1,\n ('rx', 1): 9,\n ('xt', 1): 6,\n ('gaming', 1): 3,\n ('atc', 1): 9,\n ('link', 1): 8,\n ('associate', 1): 9,\n ('earn', 1): 9,\n ('qualifying', 1): 9,\n ('purchase', 1): 9,\n ('ts', 1): 7,\n ('ready', 0): 1,\n ('us', 0): 4,\n ('stock', 0): 7,\n ('market', 0): 1,\n ('f', 0): 1,\n ('er', 0): 1,\n ('happen', 0): 1,\n ('rusia', 0): 1,\n ('invade', 0): 1,\n ('uk', 0): 3,\n ('hell', 0): 2,\n ('break', 0): 1,\n ('loose', 0): 3,\n ('good', 0): 1,\n ('wall', 0): 1,\n ('st', 0): 1,\n ('funds', 0): 1,\n ('military', 0): 1,\n ('jo', 0): 1,\n ('turn', 0): 2,\n ('wanna', 0): 1,\n ('make', 0): 1,\n ('big', 0): 3,\n ('bucks', 0): 1,\n ('like', 0): 2,\n ('bezo', 0): 1,\n ('tesla', 0): 1,\n ('dog', 0): 1,\n ('msi', 1): 2,\n ('gtx', 1): 1,\n ('super', 1): 1,\n ('xfx', 1): 3,\n ('speedster', 1): 3,\n ('qick', 1): 2,\n ('radeon', 1): 5,\n ('black', 1): 1,\n ('powercolor', 0): 4,\n ('red', 0): 4,\n ('devil', 0): 4,\n ('amd', 0): 3,\n ('radeon', 0): 3,\n ('rx', 0): 5,\n ('xt', 0): 4,\n ('gaming', 0): 3,\n ('graphics', 0): 2,\n ('card', 0): 2,\n ('gb', 0): 1,\n ('gddr', 0): 1,\n ('memory', 0): 1,\n ('product', 0): 1,\n ('page', 0): 1,\n ('atc', 0): 4,\n ('faster', 0): 1,\n ('affiliate', 0): 1,\n ('link', 0): 2,\n ('may', 0): 1,\n ('earn', 0): 4,\n ('money', 0): 2,\n ('eligible', 0): 1,\n ('purchase', 0): 4,\n ('reaching', 1): 1,\n ('old', 1): 1,\n ('new', 1): 2,\n ('reader', 1): 2,\n ('allroadsleadnorth', 1): 1,\n ('decision', 1): 1,\n ('shut', 1): 1,\n ('westland', 1): 1,\n ('mean', 1): 1,\n ('copy', 1): 1,\n ('difficult', 1): 1,\n ('come', 1): 1,\n ('next', 1): 1,\n ('month', 1): 3,\n ('thing', 1): 1,\n ('clear', 1): 1,\n ('requesting', 1): 1,\n ('bookstore', 1): 1,\n ('keep', 1): 2,\n ('activist', 0): 1,\n ('investor', 0): 1,\n ('urged', 0): 1,\n ('board', 0): 1,\n ('john', 0): 1,\n ('foley', 0): 1,\n ('put', 0): 1,\n ('bike', 0): 1,\n ('sale', 0): 1,\n ('nike', 0): 1,\n ('reportedly', 0): 1,\n ('exploring', 0): 1,\n ('sorry', 1): 1,\n ('waiting', 1): 1,\n ('simplified', 1): 1,\n ('bestseller', 1): 1,\n ('list', 1): 2,\n ('lego', 0): 1,\n ('star', 0): 1,\n ('wars', 0): 1,\n ('skywalker', 0): 1,\n ('saga', 0): 1,\n ('ps', 0): 1,\n ('playstation', 0): 1,\n ('deluxe', 0): 2,\n ('edition', 0): 2,\n ('ad', 0): 1,\n ('welcome', 1): 1,\n ('follower', 1): 1,\n ('page', 1): 1,\n ('active', 1): 1,\n ('soon', 1): 1,\n ('meantime', 1): 1,\n ('bio', 1): 1,\n ('send', 1): 1,\n ('see', 1): 1,\n ('pokemon', 1): 1,\n ('items', 1): 1,\n ('currently', 1): 1,\n ('sold', 1): 1,\n ('click', 1): 1,\n ('exchange', 0): 1,\n ('tech', 0): 1,\n ('hqs', 0): 1,\n ('look', 0): 1,\n ('many', 0): 1,\n ('fortune', 0): 1,\n ('hp', 0): 1,\n ('oracle', 0): 1,\n ('moving', 0): 1,\n ('texas', 0): 1,\n ('see', 0): 1,\n ('hey', 0): 1,\n ('second', 0): 1,\n ('hq', 0): 1,\n ('coming', 0): 1,\n ('bail', 0): 1,\n ('blue', 0): 1,\n ('state', 0): 1,\n ('hole', 0): 1,\n ('condition', 0): 1,\n ('rog', 1): 1,\n ('strix', 1): 1,\n ('lc', 1): 1,\n ('amd', 1): 2,\n ('edition', 1): 1,\n ('nah', 1): 1,\n ('every', 1): 1,\n ('tried', 1): 1,\n ('always', 1): 1,\n ('hunting', 1): 1,\n ('since', 1): 2,\n ('march', 1): 1,\n ('guess', 1): 1,\n ('try', 1): 1,\n ('ebay', 1): 1,\n ('high', 1): 1,\n ('shipping', 1): 1,\n ('luck', 1): 1,\n ('nz', 1): 1,\n ('store', 1): 1,\n ('coming', 1): 1,\n ('monday', 1): 1,\n ('rest', 1): 1,\n ('tuesday', 1): 1,\n ('kid', 1): 2,\n ('reading', 1): 1,\n ('used', 1): 2,\n ('go', 1): 2,\n ('library', 1): 3,\n ('classroom', 1): 1,\n ('school', 1): 1,\n ('needed', 1): 1,\n ('hundred', 1): 1,\n ('associate', 0): 3,\n ('qualifying', 0): 3,\n ('ts', 0): 1,\n ('actually', 1): 1,\n ('option', 1): 1,\n ('hourly', 1): 1,\n ('employee', 1): 1,\n ('got', 1): 2,\n ('rid', 1): 1,\n ('starting', 1): 1,\n ('wage', 1): 1,\n ('dollar', 1): 1,\n ('hour', 1): 1,\n ('would', 1): 1,\n ('nice', 1): 1,\n ('get', 1): 1,\n ('started', 1): 1,\n ('mech', 1): 1,\n ('oc', 1): 1,\n ('url', 0): 2,\n ('unable', 1): 1,\n ('resolve', 1): 2,\n ('customer', 1): 1,\n ('account', 1): 3,\n ('issue', 1): 2,\n ('relation', 1): 1,\n ('seller', 1): 1,\n ('kindly', 1): 1,\n ('give', 1): 1,\n ('permission', 1): 3,\n ('pick', 1): 2,\n ('asap', 1): 1,\n ('resolving', 1): 1,\n ('end', 1): 1,\n ('done', 1): 1,\n ('everything', 1): 1,\n ('contact', 1): 1,\n ('nt', 1): 1,\n ('solution', 1): 1,\n ('gigabyte', 1): 1,\n ('aorus', 1): 1,\n ('xtreme', 1): 1,\n ('waterforce', 1): 1,\n ('ultimate', 0): 1,\n ('graph', 0): 1,\n ('rxxt', 0): 1,\n ('matter', 1): 1,\n ('stucked', 1): 1,\n ('fc', 1): 2,\n ('three', 1): 2,\n ('plz', 1): 1,\n ('allow', 1): 1,\n ('stuck', 1): 1,\n ('charge', 1): 1,\n ('piling', 1): 1,\n ('day', 1): 2,\n ('product', 1): 1,\n ('depreciating', 1): 1,\n ('ur', 1): 1,\n ('hasnt', 1): 1,\n ('taken', 1): 1,\n ('follow', 1): 1,\n ('plzgive', 1): 1,\n ('powercolor', 1): 1,\n ('hellhound', 1): 1,\n ('graphics', 1): 2,\n ('card', 1): 2,\n ('gb', 1): 1,\n ('g', 1): 1,\n ('url', 1): 2,\n ('swft', 1): 1,\n ('core', 1): 1,\n ('shoot', 1): 1,\n ('higher', 1): 1,\n ('acquisition', 1): 1,\n ('considering', 1): 1,\n ('making', 1): 1,\n ('order', 1): 1,\n ('app', 1): 1,\n ('premium', 1): 1,\n ('trusted', 1): 1,\n ('garansi', 1): 1,\n ('fast', 1): 1,\n ('resp', 1): 1,\n ('wa', 1): 1,\n ('wallet', 1): 1,\n ('n', 1): 1,\n ('qris', 1): 1,\n ('tags', 1): 1,\n ('wtb', 1): 1,\n ('wts', 1): 1,\n ('neftlix', 1): 1,\n ('wetv', 1): 1,\n ('youtube', 1): 1,\n ('wattpad', 1): 1,\n ('vidio', 1): 1,\n ('alightmotion', 1): 1,\n ('appmuss', 1): 1,\n ('scrib', 1): 1,\n ('viu', 1): 1,\n ('iqiyi', 1): 1,\n ('piscart', 1): 1,\n ('vscox', 1): 1,\n ('iflix', 1): 1,\n ('hbo', 1): 1,\n ('disneyhotstar', 1): 1,\n ('grammly', 1): 1,\n ('ask', 1): 1,\n ('zonaba', 1): 1,\n ('zonauang', 1): 1}"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = build_frequency(df['Tweets'], df['Sentiment'])\n",
    "freqs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon', 'amd', 'amp', 'apple', 'associate', 'asus', 'atc', 'bbc', 'best', 'bid', 'big', 'biggest', 'binance', 'binancepay', 'bnb', 'book', 'bucks', 'buschlightclash', 'buy', 'card', 'cassie', 'cavaliers', 'cedi', 'change', 'check', 'climate', 'coin', 'comeback', 'coming', 'companies', 'company', 'convoy', 'day', 'deal', 'devil', 'dome', 'earn', 'earthquake', 'echo', 'edition', 'eth', 'ethereum', 'euphoria', 'exaggerating', 'exploring', 'far', 'fortune', 'galvanizes', 'gaming', 'gb', 'glass', 'going', 'good', 'google', 'got', 'graphics', 'gt', 'headline', 'hell', 'ikea', 'illegal', 'including', 'kevin', 'kindle', 'latest', 'lead', 'like', 'link', 'list', 'love', 'lt', 'mary', 'mattthomas', 'membership', 'money', 'month', 'msi', 'new', 'news', 'nike', 'offer', 'open', 'osman', 'ottawa', 'pacers', 'page', 'peloton', 'permission', 'pick', 'politico', 'potential', 'powercolor', 'price', 'prices', 'prime', 'product', 'progress', 'protector', 'ps', 'purchase', 'qick', 'qualifying', 'radeon', 'raised', 'really', 'red', 'report', 'reportedly', 'resolve', 'restock', 'right', 'ripple', 'rx', 'sale', 'say', 'second', 'secret', 'share', 'source', 'speedster', 'st', 'star', 'stock', 'study', 'target', 'team', 'tech', 'thing', 'time', 'trucker', 'ts', 'turn', 'uk', 'url', 'usdt', 'walmart', 'way', 'win', 'world', 'worldwide', 'xfx', 'xrp', 'xt', 'yahoo', 'year', 'zendaya']\n",
      "{'lt': 70, 'ethereum': 41, 'price': 92, 'gt': 56, 'eth': 40, 'usdt': 134, 'binance': 12, 'check': 24, 'headline': 57, 'news': 78, 'cedi': 22, 'osman': 82, 'kevin': 62, 'love': 69, 'team': 125, 'lead': 65, 'cavaliers': 21, 'biggest': 11, 'comeback': 27, 'win': 137, 'year': 144, 'pacers': 84, 'amazon': 0, 'turn': 131, 'coin': 26, 'bnb': 14, 'share': 117, 'dome': 35, 'protector': 97, 'big': 10, 'sale': 113, 'glass': 50, 'really': 104, 'apple': 3, 'buy': 18, 'peloton': 86, 'climate': 25, 'change': 23, 'company': 30, 'exaggerating': 43, 'progress': 96, 'study': 123, 'companies': 29, 'including': 61, 'google': 53, 'ikea': 59, 'target': 124, 'report': 106, 'time': 128, 'st': 120, 'book': 15, 'potential': 90, 'ottawa': 83, 'trucker': 129, 'convoy': 31, 'galvanizes': 47, 'far': 45, 'right': 110, 'worldwide': 139, 'politico': 89, 'euphoria': 42, 'mary': 71, 'mattthomas': 72, 'buschlightclash': 17, 'ripple': 111, 'xrp': 141, 'cassie': 20, 'binancepay': 13, 'zendaya': 145, 'prime': 94, 'membership': 73, 'prices': 93, 'way': 136, 'fortune': 46, 'world': 138, 'amp': 2, 'illegal': 60, 'yahoo': 143, 'latest': 64, 'offer': 80, 'deal': 33, 'bbc': 7, 'earthquake': 37, 'bucks': 16, 'exploring': 44, 'source': 118, 'say': 114, 'nike': 79, 'bid': 9, 'reportedly': 107, 'thing': 127, 'going': 51, 'day': 32, 'raised': 103, 'second': 115, 'echo': 38, 'secret': 116, 'kindle': 63, 'tech': 126, 'good': 52, 'uk': 132, 'star': 121, 'open': 81, 'ps': 98, 'restock': 109, 'best': 8, 'walmart': 135, 'stock': 122, 'asus': 5, 'rx': 112, 'xt': 142, 'gaming': 48, 'atc': 6, 'link': 67, 'associate': 4, 'earn': 36, 'qualifying': 101, 'purchase': 99, 'ts': 130, 'hell': 58, 'like': 66, 'msi': 76, 'xfx': 140, 'speedster': 119, 'qick': 100, 'radeon': 102, 'powercolor': 91, 'red': 105, 'devil': 34, 'amd': 1, 'graphics': 55, 'card': 19, 'gb': 49, 'product': 95, 'page': 85, 'money': 74, 'new': 77, 'month': 75, 'list': 68, 'edition': 39, 'coming': 28, 'got': 54, 'url': 133, 'resolve': 108, 'permission': 87, 'pick': 88}\n",
      "[[0 0 0 ... 0 1 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [2 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hlinh\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vectorizer = CountVectorizer(max_df= 0.9, min_df=2, max_features=1000, stop_words='english')\n",
    "\n",
    "# Bag-of-words feature matrix\n",
    "bow = bow_vectorizer.fit_transform(df['Tweets'])\n",
    "\n",
    "print(bow_vectorizer.get_feature_names())\n",
    "# Associate the indices with each unique word\n",
    "print(bow_vectorizer.vocabulary_)\n",
    "# Print the numerical feature vector\n",
    "print(bow.toarray())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df= 0.9, min_df=2, max_features=1000, stop_words='english')\n",
    "\n",
    "# TFIDF feature matrix\n",
    "tfidf = tfidf_vectorizer.fit_transform(df['Tweets'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "0.923076923076923"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "y = df['Sentiment'].values.astype('float')\n",
    "\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(bow, y, random_state=42, test_size=0.2)\n",
    "lreg = LogisticRegression()\n",
    "lreg.fit(X_train_bow, y_train_bow) # training the model\n",
    "prediction = lreg.predict_proba(X_test_bow) # predicting on the validation set\n",
    "prediction_float = prediction[:,1] >= 0.3 # if prediction >= 0.2 then 1 or else 0\n",
    "prediction_float = prediction_float.astype('float')\n",
    "f1_score(y_test_bow, prediction_float) # calculate f1 score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.86      1.00      0.92        12\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.43      0.50      0.46        14\n",
      "weighted avg       0.73      0.86      0.79        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hlinh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hlinh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hlinh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_bow, prediction_float))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "0.923076923076923"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(tfidf, y, random_state=42, test_size=0.2)\n",
    "lreg_tfidf = LogisticRegression()\n",
    "lreg_tfidf.fit(X_train_tfidf, y_train_tfidf) # training the model\n",
    "prediction = lreg_tfidf.predict_proba(X_test_tfidf) # predicting on the validation set\n",
    "prediction_float = prediction[:,1] >= 0.3 # if prediction >= 0.2 then 1 or else 0\n",
    "prediction_float = prediction_float.astype('float')\n",
    "f1_score(y_test_tfidf, prediction_float) # calculate f1 score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}